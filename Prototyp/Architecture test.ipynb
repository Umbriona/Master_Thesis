{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "## imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import models.component as cP\n",
    "import models.data_process as dP\n",
    "import math\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "# Plot Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global\n",
    "EPOCH = 100\n",
    "fps_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_class1():\n",
    "    \n",
    "    fps_dict = dP.process_data_np(ds_name = 'LD50_Test_data', pool_size = 4)\n",
    "\n",
    "    fps1_train = fps_dict['fps1_train_np']\n",
    "    fps1_test = fps_dict['fps1_test_np']\n",
    "    labels1_train = fps_dict['labels1_train_np']\n",
    "    labels1_test = fps_dict['labels1_test_np']\n",
    "    i_lr = 0.005\n",
    "    lastLoss = 0\n",
    "    layers_dim = np.array([256, 64, 10], dtype = np.float32)\n",
    "    fps_dim = 2048\n",
    "    batch_size = 64\n",
    "    with tf.device('/gpu:1'):\n",
    "\n",
    "        labels = tf.placeholder(tf.float32, shape=[None, 10], name = 'labels')\n",
    "        is_train_enc = tf.placeholder(tf.bool, name = 'is_train_enc')\n",
    "        fps = tf.placeholder(tf.float32, shape = [None, 2048,2], name ='fps')\n",
    "        lr_1 = tf.placeholder(tf.float32, name = 'lr_1')\n",
    "        \n",
    "        predict, _ = cP.cnn_encoder(fps, fps_dim, layers_dim, is_train_enc, reuse=False)\n",
    "        classifyer1_loss = tf.losses.softmax_cross_entropy(labels,predict)\n",
    "        \n",
    "        predicted_labels = tf.one_hot(tf.math.argmax(predict, axis = 1), 10, on_value = 1.0, off_value = 0.0)\n",
    "        classifyer1_acc = tf.metrics.accuracy(labels,predicted_labels)\n",
    "        \n",
    "        t_vars = tf.trainable_variables()\n",
    "        enc_vars = [var for var in t_vars if 'encode' in var.name]\n",
    "        \n",
    "        trainer_enc = tf.train.AdamOptimizer(learning_rate =lr_1, beta1=0.9, beta2=0.999,\n",
    "                                             epsilon=1e-08, use_locking=False,\n",
    "                                             name='Adam_encoder').minimize(classifyer1_loss, var_list=enc_vars)\n",
    "        \n",
    "\n",
    "        \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    num_batch_epoch = math.floor(len(fps1_train)/batch_size)\n",
    "\n",
    "    for i in range(EPOCH):\n",
    "        batch1_train = dP.batch_gen(fps1_train, labels1_train, batch_size = batch_size, FLAG = True)\n",
    "        batch1_val = dP.batch_gen(fps1_test, labels1_test, batch_size = batch_size, FLAG = True) \n",
    "\n",
    "        for j in range(num_batch_epoch):\n",
    "\n",
    "            dict_train =  {fps: batch1_train['fps'][j], labels: batch1_train['label'][j], is_train_enc: True, lr_1: i_lr}\n",
    "            sess.run([trainer_enc], feed_dict = dict_train)\n",
    "\n",
    "        dict_train_loss = {fps: fps1_train, labels: labels1_train, is_train_enc: False}\n",
    "        trainLoss, trainAcc = sess.run([classifyer1_loss, classifyer1_acc], feed_dict = dict_train_loss)\n",
    "        if i%5 == 0 and i != 0:\n",
    "            if lastLoss - trainLoss <= 0.00000:\n",
    "                i_lr = max([i_lr * 0.5, 0.00001])\n",
    "            lastLoss = trainLoss \n",
    "        dict_val =  {fps: fps1_test, labels: labels1_test, is_train_enc: False}\n",
    "        valLoss, valAcc = sess.run([classifyer1_loss, classifyer1_acc], feed_dict = dict_val)\n",
    "        #encoder_dict={fps: fps_test, is_train_enc: False}\n",
    "        #print(sess.run(predict, feed_dict = encoder_dict))\n",
    "        \n",
    "        print('1 %f trainLoss = %f valLoss = %f trainAcc = %f valAcc = %f' % (i_lr, trainLoss, valLoss, trainAcc[0], valAcc[0]))\n",
    "    sess.close()\n",
    "\n",
    "def train_class2():\n",
    "    fps_dict = dP.process_data_np(ds_name = 'LD50_Test_data', pool_size = 4)\n",
    "\n",
    "    fps_train = fps_dict['fps2_train_np']\n",
    "    fps_test = fps_dict['fps2_test_np']\n",
    "    labels_train = fps_dict['labels2_train_np']\n",
    "    labels_test = fps_dict['labels2_test_np']\n",
    "    i_lr = 0.01\n",
    "    lastLoss = 0\n",
    "    layers_dim = np.array([256, 64, 10], dtype = np.float32)\n",
    "    fps_dim = 512\n",
    "    batch_size = 64\n",
    "\n",
    "        \n",
    "    with tf.device('/gpu:0'):\n",
    "        labels2 = tf.placeholder(tf.float32, shape=[None, 10], name = 'labels2')\n",
    "        is_train_dense = tf.placeholder(tf.bool, name = 'is_train_dense')\n",
    "        fps2 = tf.placeholder(tf.float32, shape = [None, 512], name ='fps2')\n",
    "        lr_2 = tf.placeholder(tf.float32, name = 'lr_2')\n",
    "        predict2 = cP.dense_encoder(fps2, 512, layers_dim, is_train_dense, reuse=False)\n",
    "        classifyer2_loss = tf.losses.softmax_cross_entropy(labels2,predict2)\n",
    "        predicted_labels = tf.one_hot(tf.math.argmax(predict2, axis = 1), 10, on_value = 1.0, off_value = 0.0)\n",
    "        classifyer2_acc = tf.metrics.accuracy(labels2,predicted_labels)\n",
    "        \n",
    "        t_vars = tf.trainable_variables()\n",
    "        dense_vars = [var for var in t_vars if 'dense_class' in var.name]\n",
    "        trainer_dense = tf.train.AdamOptimizer(learning_rate =lr_2, beta1=0.9, beta2=0.999,\n",
    "                                             epsilon=1e-08, use_locking=False,\n",
    "                                             name='Adam_encoder').minimize(classifyer2_loss, var_list=dense_vars)\n",
    "        \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    num_batch_epoch = math.floor(len(fps_train)/batch_size)\n",
    "\n",
    "    for i in range(EPOCH):\n",
    "        batch1_train = dP.batch_gen(fps_train, labels_train, batch_size = batch_size, FLAG = True)\n",
    "        batch1_val = dP.batch_gen(fps_test, labels_test, batch_size = batch_size, FLAG = True) \n",
    "\n",
    "        for j in range(num_batch_epoch):\n",
    "\n",
    "            dict_train =  {fps2: batch1_train['fps'][j], labels2: batch1_train['label'][j], is_train_dense: True, lr_2: i_lr}\n",
    "            sess.run([trainer_dense], feed_dict = dict_train)\n",
    "\n",
    "        dict_train_loss = {fps2: fps_train, labels2: labels_train, is_train_dense: False}\n",
    "        trainLoss, trainAcc = sess.run([classifyer2_loss, classifyer2_acc], feed_dict = dict_train_loss)\n",
    "        if i%5 == 0 and i != 0:\n",
    "            if lastLoss - trainLoss <= 0.00000:\n",
    "                i_lr = max([i_lr * 0.5, 0.00001])\n",
    "            lastLoss = trainLoss \n",
    "        dict_val =  {fps2: fps_test, labels2: labels_test, is_train_dense: False}\n",
    "        valLoss, valAcc = sess.run([classifyer2_loss, classifyer2_acc], feed_dict = dict_val)\n",
    "        #encoder_dict={fps: fps_test, is_train_enc: False}\n",
    "        #print(sess.run(predict, feed_dict = encoder_dict))\n",
    "        \n",
    "        print('2 %f trainLoss = %f valLoss = %f trainAcc = %f valAcc = %f' % (i_lr, trainLoss, valLoss, trainAcc[0], valAcc[0]))\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.010000 trainLoss = 1.364407 valLoss = 1.425479 trainAcc = 0.000000 valAcc = 0.919290\n",
      "2 0.010000 trainLoss = 1.185427 valLoss = 1.382215 trainAcc = 0.918512 valAcc = 0.923164\n",
      "2 0.010000 trainLoss = 1.108067 valLoss = 1.373816 trainAcc = 0.922472 valAcc = 0.925707\n",
      "2 0.010000 trainLoss = 1.022283 valLoss = 1.333350 trainAcc = 0.925253 valAcc = 0.927469\n",
      "2 0.010000 trainLoss = 0.970886 valLoss = 1.301398 trainAcc = 0.927227 valAcc = 0.929114\n",
      "2 0.005000 trainLoss = 0.899935 valLoss = 1.284559 trainAcc = 0.928811 valAcc = 0.930718\n",
      "1 0.005000 trainLoss = 2.097891 valLoss = 2.094016 trainAcc = 0.000000 valAcc = 0.843816\n",
      "2 0.005000 trainLoss = 0.808375 valLoss = 1.279806 trainAcc = 0.930449 valAcc = 0.932722\n",
      "2 0.005000 trainLoss = 0.788193 valLoss = 1.293470 trainAcc = 0.932413 valAcc = 0.934406\n",
      "2 0.005000 trainLoss = 0.768822 valLoss = 1.325312 trainAcc = 0.934064 valAcc = 0.935899\n",
      "1 0.005000 trainLoss = 1.847861 valLoss = 1.830327 trainAcc = 0.844463 valAcc = 0.869694\n",
      "2 0.005000 trainLoss = 0.737419 valLoss = 1.295521 trainAcc = 0.935561 valAcc = 0.937124\n",
      "2 0.005000 trainLoss = 0.705054 valLoss = 1.320298 trainAcc = 0.936781 valAcc = 0.938446\n",
      "2 0.005000 trainLoss = 0.701808 valLoss = 1.308663 trainAcc = 0.938136 valAcc = 0.939466\n",
      "1 0.005000 trainLoss = 1.724250 valLoss = 1.691065 trainAcc = 0.873231 valAcc = 0.881231\n",
      "2 0.005000 trainLoss = 0.650484 valLoss = 1.289220 trainAcc = 0.939191 valAcc = 0.940635\n",
      "2 0.005000 trainLoss = 0.636589 valLoss = 1.307181 trainAcc = 0.940374 valAcc = 0.941697\n",
      "2 0.005000 trainLoss = 0.611988 valLoss = 1.301226 trainAcc = 0.941413 valAcc = 0.942863\n",
      "1 0.005000 trainLoss = 1.691283 valLoss = 1.656568 trainAcc = 0.882820 valAcc = 0.886696\n",
      "2 0.005000 trainLoss = 0.609372 valLoss = 1.309687 trainAcc = 0.942629 valAcc = 0.943929\n",
      "2 0.005000 trainLoss = 0.623872 valLoss = 1.350901 trainAcc = 0.943655 valAcc = 0.944695\n",
      "2 0.005000 trainLoss = 0.559274 valLoss = 1.317640 trainAcc = 0.944442 valAcc = 0.945571\n",
      "1 0.005000 trainLoss = 1.682310 valLoss = 1.648136 trainAcc = 0.887614 valAcc = 0.889884\n",
      "2 0.005000 trainLoss = 0.566976 valLoss = 1.311535 trainAcc = 0.945332 valAcc = 0.946373\n",
      "2 0.005000 trainLoss = 0.543629 valLoss = 1.328907 trainAcc = 0.946128 valAcc = 0.947226\n",
      "2 0.005000 trainLoss = 0.534560 valLoss = 1.310189 trainAcc = 0.946996 valAcc = 0.948069\n",
      "1 0.002500 trainLoss = 1.676857 valLoss = 1.645038 trainAcc = 0.890491 valAcc = 0.891973\n",
      "2 0.005000 trainLoss = 0.517863 valLoss = 1.342037 trainAcc = 0.947833 valAcc = 0.948800\n",
      "2 0.005000 trainLoss = 0.530109 valLoss = 1.351119 trainAcc = 0.948561 valAcc = 0.949389\n",
      "2 0.005000 trainLoss = 0.528913 valLoss = 1.307044 trainAcc = 0.949170 valAcc = 0.950003\n",
      "1 0.002500 trainLoss = 1.675363 valLoss = 1.647016 trainAcc = 0.892409 valAcc = 0.893447\n",
      "2 0.005000 trainLoss = 0.488463 valLoss = 1.323379 trainAcc = 0.949793 valAcc = 0.950715\n",
      "2 0.005000 trainLoss = 0.509078 valLoss = 1.317244 trainAcc = 0.950495 valAcc = 0.951283\n",
      "2 0.005000 trainLoss = 0.504838 valLoss = 1.324196 trainAcc = 0.951074 valAcc = 0.951816\n",
      "1 0.002500 trainLoss = 1.673670 valLoss = 1.644414 trainAcc = 0.893779 valAcc = 0.894543\n",
      "2 0.005000 trainLoss = 0.486768 valLoss = 1.315746 trainAcc = 0.951620 valAcc = 0.952324\n",
      "2 0.005000 trainLoss = 0.459674 valLoss = 1.318997 trainAcc = 0.952130 valAcc = 0.952931\n",
      "2 0.005000 trainLoss = 0.459843 valLoss = 1.341651 trainAcc = 0.952728 valAcc = 0.953419\n",
      "1 0.002500 trainLoss = 1.672981 valLoss = 1.646303 trainAcc = 0.894806 valAcc = 0.895391\n",
      "2 0.005000 trainLoss = 0.459385 valLoss = 1.331709 trainAcc = 0.953223 valAcc = 0.953874\n",
      "2 0.005000 trainLoss = 0.476430 valLoss = 1.332427 trainAcc = 0.953686 valAcc = 0.954346\n",
      "2 0.005000 trainLoss = 0.470113 valLoss = 1.340069 trainAcc = 0.954147 valAcc = 0.954743\n",
      "1 0.002500 trainLoss = 1.671911 valLoss = 1.645015 trainAcc = 0.895605 valAcc = 0.896062\n",
      "2 0.005000 trainLoss = 0.438966 valLoss = 1.312475 trainAcc = 0.954552 valAcc = 0.955165\n",
      "2 0.005000 trainLoss = 0.458357 valLoss = 1.342175 trainAcc = 0.954980 valAcc = 0.955539\n",
      "2 0.005000 trainLoss = 0.434187 valLoss = 1.322059 trainAcc = 0.955356 valAcc = 0.955956\n",
      "1 0.002500 trainLoss = 1.673085 valLoss = 1.646927 trainAcc = 0.896242 valAcc = 0.896612\n",
      "2 0.005000 trainLoss = 0.437842 valLoss = 1.344047 trainAcc = 0.955779 valAcc = 0.956363\n",
      "2 0.005000 trainLoss = 0.442389 valLoss = 1.323937 trainAcc = 0.956189 valAcc = 0.956694\n",
      "2 0.005000 trainLoss = 0.403719 valLoss = 1.344972 trainAcc = 0.956528 valAcc = 0.957091\n",
      "1 0.002500 trainLoss = 1.669507 valLoss = 1.640223 trainAcc = 0.896765 valAcc = 0.897068\n",
      "2 0.005000 trainLoss = 0.441037 valLoss = 1.339752 trainAcc = 0.956923 valAcc = 0.957403\n",
      "2 0.002500 trainLoss = 0.444382 valLoss = 1.323281 trainAcc = 0.957231 valAcc = 0.957697\n",
      "2 0.002500 trainLoss = 0.374489 valLoss = 1.320824 trainAcc = 0.957538 valAcc = 0.958069\n",
      "1 0.002500 trainLoss = 1.670754 valLoss = 1.641742 trainAcc = 0.897201 valAcc = 0.897453\n",
      "2 0.002500 trainLoss = 0.368469 valLoss = 1.328843 trainAcc = 0.957910 valAcc = 0.958419\n",
      "2 0.002500 trainLoss = 0.375081 valLoss = 1.329613 trainAcc = 0.958260 valAcc = 0.958739\n",
      "2 0.002500 trainLoss = 0.363463 valLoss = 1.335855 trainAcc = 0.958582 valAcc = 0.959059\n",
      "1 0.002500 trainLoss = 1.667414 valLoss = 1.639716 trainAcc = 0.897570 valAcc = 0.897783\n",
      "2 0.002500 trainLoss = 0.354540 valLoss = 1.338795 trainAcc = 0.958900 valAcc = 0.959373\n",
      "2 0.002500 trainLoss = 0.350288 valLoss = 1.341629 trainAcc = 0.959223 valAcc = 0.959674\n",
      "2 0.002500 trainLoss = 0.368070 valLoss = 1.330208 trainAcc = 0.959524 valAcc = 0.959959\n",
      "1 0.002500 trainLoss = 1.667315 valLoss = 1.642178 trainAcc = 0.897887 valAcc = 0.898068\n",
      "2 0.002500 trainLoss = 0.361638 valLoss = 1.317029 trainAcc = 0.959813 valAcc = 0.960230\n",
      "2 0.002500 trainLoss = 0.370550 valLoss = 1.332833 trainAcc = 0.960088 valAcc = 0.960488\n",
      "2 0.002500 trainLoss = 0.350497 valLoss = 1.328403 trainAcc = 0.960351 valAcc = 0.960752\n",
      "1 0.002500 trainLoss = 1.671672 valLoss = 1.639219 trainAcc = 0.898161 valAcc = 0.898316\n",
      "2 0.002500 trainLoss = 0.366806 valLoss = 1.338489 trainAcc = 0.960605 valAcc = 0.960987\n",
      "2 0.002500 trainLoss = 0.364464 valLoss = 1.327896 trainAcc = 0.960844 valAcc = 0.961214\n",
      "2 0.002500 trainLoss = 0.347842 valLoss = 1.330890 trainAcc = 0.961073 valAcc = 0.961438\n",
      "1 0.002500 trainLoss = 1.665369 valLoss = 1.642797 trainAcc = 0.898401 valAcc = 0.898536\n",
      "2 0.002500 trainLoss = 0.359244 valLoss = 1.324364 trainAcc = 0.961305 valAcc = 0.961660\n",
      "2 0.001250 trainLoss = 0.352296 valLoss = 1.328139 trainAcc = 0.961533 valAcc = 0.961884\n",
      "2 0.001250 trainLoss = 0.337477 valLoss = 1.331115 trainAcc = 0.961753 valAcc = 0.962098\n",
      "1 0.002500 trainLoss = 1.667259 valLoss = 1.642785 trainAcc = 0.898612 valAcc = 0.898730\n",
      "2 0.001250 trainLoss = 0.336600 valLoss = 1.323870 trainAcc = 0.961968 valAcc = 0.962304\n",
      "2 0.001250 trainLoss = 0.323719 valLoss = 1.327891 trainAcc = 0.962176 valAcc = 0.962505\n",
      "2 0.001250 trainLoss = 0.334878 valLoss = 1.324885 trainAcc = 0.962380 valAcc = 0.962697\n",
      "1 0.002500 trainLoss = 1.664384 valLoss = 1.640118 trainAcc = 0.898800 valAcc = 0.898904\n",
      "2 0.001250 trainLoss = 0.328916 valLoss = 1.328064 trainAcc = 0.962574 valAcc = 0.962887\n",
      "2 0.001250 trainLoss = 0.341080 valLoss = 1.329274 trainAcc = 0.962762 valAcc = 0.963062\n",
      "2 0.001250 trainLoss = 0.326263 valLoss = 1.329619 trainAcc = 0.962943 valAcc = 0.963243\n",
      "1 0.002500 trainLoss = 1.661139 valLoss = 1.636872 trainAcc = 0.898969 valAcc = 0.899060\n",
      "2 0.001250 trainLoss = 0.334605 valLoss = 1.334636 trainAcc = 0.963125 valAcc = 0.963415\n",
      "2 0.001250 trainLoss = 0.327914 valLoss = 1.328099 trainAcc = 0.963292 valAcc = 0.963579\n",
      "2 0.000625 trainLoss = 0.329393 valLoss = 1.329597 trainAcc = 0.963465 valAcc = 0.963747\n",
      "1 0.002500 trainLoss = 1.655956 valLoss = 1.633275 trainAcc = 0.899120 valAcc = 0.899201\n",
      "2 0.000625 trainLoss = 0.321064 valLoss = 1.334198 trainAcc = 0.963627 valAcc = 0.963902\n",
      "2 0.000625 trainLoss = 0.322683 valLoss = 1.331185 trainAcc = 0.963786 valAcc = 0.964056\n",
      "2 0.000625 trainLoss = 0.321190 valLoss = 1.332120 trainAcc = 0.963943 valAcc = 0.964208\n",
      "1 0.002500 trainLoss = 1.662985 valLoss = 1.637362 trainAcc = 0.899257 valAcc = 0.899330\n",
      "2 0.000625 trainLoss = 0.316250 valLoss = 1.334338 trainAcc = 0.964093 valAcc = 0.964352\n",
      "2 0.000625 trainLoss = 0.323120 valLoss = 1.328099 trainAcc = 0.964242 valAcc = 0.964493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.000625 trainLoss = 0.319466 valLoss = 1.335602 trainAcc = 0.964382 valAcc = 0.964630\n",
      "2 0.000625 trainLoss = 0.311503 valLoss = 1.336716 trainAcc = 0.964521 valAcc = 0.964763\n",
      "1 0.002500 trainLoss = 1.689000 valLoss = 1.630874 trainAcc = 0.899382 valAcc = 0.899455\n",
      "2 0.000625 trainLoss = 0.309724 valLoss = 1.337143 trainAcc = 0.964653 valAcc = 0.964892\n",
      "2 0.000625 trainLoss = 0.315963 valLoss = 1.341840 trainAcc = 0.964784 valAcc = 0.965018\n",
      "1 0.002500 trainLoss = 1.667472 valLoss = 1.638782 trainAcc = 0.899499 valAcc = 0.899557\n",
      "2 0.000625 trainLoss = 0.311016 valLoss = 1.336087 trainAcc = 0.964910 valAcc = 0.965141\n",
      "2 0.000625 trainLoss = 0.309111 valLoss = 1.344336 trainAcc = 0.965037 valAcc = 0.965262\n",
      "2 0.000625 trainLoss = 0.323108 valLoss = 1.334678 trainAcc = 0.965158 valAcc = 0.965380\n",
      "2 0.000625 trainLoss = 0.314447 valLoss = 1.335642 trainAcc = 0.965275 valAcc = 0.965493\n",
      "1 0.002500 trainLoss = 1.664930 valLoss = 1.638414 trainAcc = 0.899603 valAcc = 0.899655\n",
      "2 0.000625 trainLoss = 0.314356 valLoss = 1.350692 trainAcc = 0.965392 valAcc = 0.965604\n",
      "2 0.000313 trainLoss = 0.329240 valLoss = 1.342488 trainAcc = 0.965503 valAcc = 0.965709\n",
      "2 0.000313 trainLoss = 0.315571 valLoss = 1.332271 trainAcc = 0.965609 valAcc = 0.965815\n",
      "1 0.001250 trainLoss = 1.660128 valLoss = 1.639217 trainAcc = 0.899699 valAcc = 0.899756\n",
      "2 0.000313 trainLoss = 0.308407 valLoss = 1.339937 trainAcc = 0.965715 valAcc = 0.965918\n",
      "2 0.000313 trainLoss = 0.311335 valLoss = 1.337373 trainAcc = 0.965818 valAcc = 0.966016\n",
      "2 0.000313 trainLoss = 0.307684 valLoss = 1.341879 trainAcc = 0.965918 valAcc = 0.966113\n",
      "1 0.001250 trainLoss = 1.649145 valLoss = 1.627007 trainAcc = 0.899797 valAcc = 0.899850\n",
      "2 0.000313 trainLoss = 0.310732 valLoss = 1.339586 trainAcc = 0.966016 valAcc = 0.966209\n",
      "2 0.000313 trainLoss = 0.304783 valLoss = 1.341137 trainAcc = 0.966114 valAcc = 0.966305\n",
      "2 0.000313 trainLoss = 0.302213 valLoss = 1.341173 trainAcc = 0.966211 valAcc = 0.966398\n",
      "1 0.001250 trainLoss = 1.654901 valLoss = 1.629831 trainAcc = 0.899890 valAcc = 0.899929\n",
      "2 0.000313 trainLoss = 0.309382 valLoss = 1.337595 trainAcc = 0.966306 valAcc = 0.966491\n",
      "2 0.000313 trainLoss = 0.313824 valLoss = 1.334684 trainAcc = 0.966399 valAcc = 0.966580\n",
      "2 0.000156 trainLoss = 0.316363 valLoss = 1.334857 trainAcc = 0.966490 valAcc = 0.966668\n",
      "1 0.001250 trainLoss = 1.634618 valLoss = 1.614502 trainAcc = 0.899966 valAcc = 0.900040\n",
      "2 0.000156 trainLoss = 0.308506 valLoss = 1.337641 trainAcc = 0.966576 valAcc = 0.966752\n",
      "2 0.000156 trainLoss = 0.305783 valLoss = 1.332335 trainAcc = 0.966663 valAcc = 0.966837\n",
      "2 0.000156 trainLoss = 0.309439 valLoss = 1.334724 trainAcc = 0.966747 valAcc = 0.966918\n",
      "1 0.001250 trainLoss = 1.630180 valLoss = 1.618647 trainAcc = 0.900078 valAcc = 0.900138\n",
      "2 0.000156 trainLoss = 0.304369 valLoss = 1.340498 trainAcc = 0.966829 valAcc = 0.966997\n",
      "2 0.000156 trainLoss = 0.310967 valLoss = 1.335657 trainAcc = 0.966908 valAcc = 0.967072\n",
      "2 0.000156 trainLoss = 0.306496 valLoss = 1.333572 trainAcc = 0.966987 valAcc = 0.967152\n",
      "1 0.001250 trainLoss = 1.614718 valLoss = 1.607708 trainAcc = 0.900170 valAcc = 0.900268\n",
      "2 0.000156 trainLoss = 0.304798 valLoss = 1.340518 trainAcc = 0.967065 valAcc = 0.967227\n",
      "2 0.000156 trainLoss = 0.308344 valLoss = 1.341240 trainAcc = 0.967141 valAcc = 0.967299\n",
      "2 0.000156 trainLoss = 0.304513 valLoss = 1.340674 trainAcc = 0.967213 valAcc = 0.967369\n",
      "1 0.001250 trainLoss = 1.602229 valLoss = 1.614880 trainAcc = 0.900311 valAcc = 0.900421\n",
      "1 0.001250 trainLoss = 1.604022 valLoss = 1.617184 trainAcc = 0.900457 valAcc = 0.900571\n",
      "1 0.001250 trainLoss = 1.582392 valLoss = 1.610383 trainAcc = 0.900605 valAcc = 0.900732\n",
      "1 0.001250 trainLoss = 1.574707 valLoss = 1.607493 trainAcc = 0.900763 valAcc = 0.900893\n",
      "1 0.001250 trainLoss = 1.553988 valLoss = 1.612441 trainAcc = 0.900919 valAcc = 0.901062\n",
      "1 0.001250 trainLoss = 1.536324 valLoss = 1.612316 trainAcc = 0.901097 valAcc = 0.901247\n",
      "1 0.001250 trainLoss = 1.546305 valLoss = 1.614495 trainAcc = 0.901273 valAcc = 0.901401\n",
      "1 0.001250 trainLoss = 1.532618 valLoss = 1.602370 trainAcc = 0.901431 valAcc = 0.901561\n",
      "1 0.001250 trainLoss = 1.506877 valLoss = 1.606230 trainAcc = 0.901579 valAcc = 0.901706\n",
      "1 0.001250 trainLoss = 1.496482 valLoss = 1.628946 trainAcc = 0.901730 valAcc = 0.901886\n",
      "1 0.001250 trainLoss = 1.479205 valLoss = 1.592414 trainAcc = 0.901905 valAcc = 0.902066\n",
      "1 0.001250 trainLoss = 1.457122 valLoss = 1.619599 trainAcc = 0.902094 valAcc = 0.902257\n",
      "1 0.001250 trainLoss = 1.457668 valLoss = 1.619951 trainAcc = 0.902270 valAcc = 0.902439\n",
      "1 0.001250 trainLoss = 1.444950 valLoss = 1.615971 trainAcc = 0.902453 valAcc = 0.902630\n",
      "1 0.001250 trainLoss = 1.442390 valLoss = 1.651726 trainAcc = 0.902644 valAcc = 0.902819\n",
      "1 0.001250 trainLoss = 1.396715 valLoss = 1.650929 trainAcc = 0.902818 valAcc = 0.903027\n",
      "1 0.001250 trainLoss = 1.388337 valLoss = 1.631427 trainAcc = 0.903035 valAcc = 0.903240\n",
      "1 0.001250 trainLoss = 1.369604 valLoss = 1.635789 trainAcc = 0.903241 valAcc = 0.903459\n",
      "1 0.001250 trainLoss = 1.356008 valLoss = 1.647958 trainAcc = 0.903458 valAcc = 0.903699\n",
      "1 0.001250 trainLoss = 1.345408 valLoss = 1.662069 trainAcc = 0.903699 valAcc = 0.903938\n",
      "1 0.001250 trainLoss = 1.324403 valLoss = 1.695557 trainAcc = 0.903939 valAcc = 0.904187\n",
      "1 0.001250 trainLoss = 1.322588 valLoss = 1.714691 trainAcc = 0.904176 valAcc = 0.904414\n",
      "1 0.001250 trainLoss = 1.296694 valLoss = 1.687196 trainAcc = 0.904401 valAcc = 0.904644\n",
      "1 0.001250 trainLoss = 1.327784 valLoss = 1.764838 trainAcc = 0.904636 valAcc = 0.904856\n",
      "1 0.001250 trainLoss = 1.276147 valLoss = 1.712674 trainAcc = 0.904840 valAcc = 0.905103\n",
      "1 0.001250 trainLoss = 1.268920 valLoss = 1.701854 trainAcc = 0.905086 valAcc = 0.905342\n",
      "1 0.001250 trainLoss = 1.256527 valLoss = 1.748269 trainAcc = 0.905322 valAcc = 0.905576\n",
      "1 0.001250 trainLoss = 1.213516 valLoss = 1.738301 trainAcc = 0.905557 valAcc = 0.905836\n",
      "1 0.001250 trainLoss = 1.211744 valLoss = 1.730559 trainAcc = 0.905818 valAcc = 0.906094\n",
      "1 0.001250 trainLoss = 1.197777 valLoss = 1.747382 trainAcc = 0.906070 valAcc = 0.906340\n",
      "1 0.001250 trainLoss = 1.183343 valLoss = 1.734008 trainAcc = 0.906327 valAcc = 0.906598\n",
      "1 0.001250 trainLoss = 1.165703 valLoss = 1.729565 trainAcc = 0.906585 valAcc = 0.906870\n",
      "1 0.001250 trainLoss = 1.172609 valLoss = 1.778765 trainAcc = 0.906851 valAcc = 0.907131\n",
      "1 0.001250 trainLoss = 1.141639 valLoss = 1.771326 trainAcc = 0.907105 valAcc = 0.907386\n",
      "1 0.001250 trainLoss = 1.144049 valLoss = 1.785826 trainAcc = 0.907358 valAcc = 0.907621\n",
      "1 0.001250 trainLoss = 1.125639 valLoss = 1.748623 trainAcc = 0.907595 valAcc = 0.907877\n",
      "1 0.001250 trainLoss = 1.118359 valLoss = 1.770109 trainAcc = 0.907853 valAcc = 0.908134\n",
      "1 0.001250 trainLoss = 1.082441 valLoss = 1.766588 trainAcc = 0.908106 valAcc = 0.908387\n",
      "1 0.001250 trainLoss = 1.096104 valLoss = 1.804969 trainAcc = 0.908364 valAcc = 0.908635\n",
      "1 0.001250 trainLoss = 1.109613 valLoss = 1.814129 trainAcc = 0.908607 valAcc = 0.908853\n",
      "1 0.001250 trainLoss = 1.083329 valLoss = 1.791021 trainAcc = 0.908818 valAcc = 0.909080\n",
      "1 0.001250 trainLoss = 1.064555 valLoss = 1.783452 trainAcc = 0.909046 valAcc = 0.909311\n",
      "1 0.001250 trainLoss = 1.087587 valLoss = 1.784278 trainAcc = 0.909284 valAcc = 0.909536\n",
      "1 0.001250 trainLoss = 1.039517 valLoss = 1.792782 trainAcc = 0.909510 valAcc = 0.909780\n",
      "1 0.001250 trainLoss = 1.022815 valLoss = 1.779238 trainAcc = 0.909748 valAcc = 0.910021\n",
      "1 0.001250 trainLoss = 1.048515 valLoss = 1.829338 trainAcc = 0.909985 valAcc = 0.910245\n",
      "1 0.001250 trainLoss = 0.998830 valLoss = 1.816919 trainAcc = 0.910214 valAcc = 0.910493\n",
      "1 0.001250 trainLoss = 0.985369 valLoss = 1.803761 trainAcc = 0.910455 valAcc = 0.910743\n",
      "1 0.001250 trainLoss = 0.954050 valLoss = 1.875095 trainAcc = 0.910708 valAcc = 0.911001\n",
      "1 0.001250 trainLoss = 0.946729 valLoss = 1.855235 trainAcc = 0.910952 valAcc = 0.911252\n",
      "1 0.001250 trainLoss = 0.922571 valLoss = 1.850354 trainAcc = 0.911205 valAcc = 0.911509\n",
      "1 0.001250 trainLoss = 0.943303 valLoss = 1.831364 trainAcc = 0.911464 valAcc = 0.911747\n",
      "1 0.001250 trainLoss = 0.934503 valLoss = 1.862099 trainAcc = 0.911708 valAcc = 0.911993\n",
      "1 0.001250 trainLoss = 0.888478 valLoss = 1.837784 trainAcc = 0.911947 valAcc = 0.912252\n",
      "1 0.001250 trainLoss = 0.881486 valLoss = 1.819000 trainAcc = 0.912210 valAcc = 0.912510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.001250 trainLoss = 0.886042 valLoss = 1.831745 trainAcc = 0.912462 valAcc = 0.912762\n",
      "1 0.001250 trainLoss = 0.846883 valLoss = 1.839691 trainAcc = 0.912721 valAcc = 0.913046\n",
      "1 0.001250 trainLoss = 0.814953 valLoss = 1.851719 trainAcc = 0.913000 valAcc = 0.913335\n",
      "1 0.001250 trainLoss = 0.909949 valLoss = 1.877985 trainAcc = 0.913293 valAcc = 0.913560\n",
      "1 0.001250 trainLoss = 0.838479 valLoss = 1.863627 trainAcc = 0.913514 valAcc = 0.913812\n",
      "1 0.001250 trainLoss = 0.812110 valLoss = 1.879627 trainAcc = 0.913762 valAcc = 0.914083\n",
      "1 0.001250 trainLoss = 0.778242 valLoss = 1.863938 trainAcc = 0.914029 valAcc = 0.914362\n",
      "1 0.001250 trainLoss = 0.788232 valLoss = 1.861355 trainAcc = 0.914314 valAcc = 0.914641\n",
      "1 0.001250 trainLoss = 0.783237 valLoss = 1.862386 trainAcc = 0.914595 valAcc = 0.914915\n",
      "1 0.001250 trainLoss = 0.795431 valLoss = 1.863848 trainAcc = 0.914862 valAcc = 0.915171\n",
      "1 0.001250 trainLoss = 0.756165 valLoss = 1.870702 trainAcc = 0.915118 valAcc = 0.915445\n",
      "1 0.001250 trainLoss = 0.731016 valLoss = 1.880200 trainAcc = 0.915397 valAcc = 0.915735\n",
      "1 0.001250 trainLoss = 0.740821 valLoss = 1.860150 trainAcc = 0.915685 valAcc = 0.916013\n",
      "1 0.001250 trainLoss = 0.723548 valLoss = 1.868856 trainAcc = 0.915961 valAcc = 0.916298\n"
     ]
    }
   ],
   "source": [
    "## Main\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    Process(target=train_class1).start()\n",
    "    Process(target=train_class2).start()\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
