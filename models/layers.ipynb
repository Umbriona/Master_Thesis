{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "## Activation functions\n",
    "\n",
    "#Leaky relu\n",
    "def lrelu(x, n = None, leak=0.2): \n",
    "    return tf.maximum(x, leak * x, name=n) \n",
    "\n",
    "#Heavside\n",
    "def heavside(x, n):\n",
    "    return tf.maximum(0.0,tf.sign(x), name = n)\n",
    "\n",
    "#Linear\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def denseLayer(input, out_size, batch_norm = True, activation = lrelu, reuse = False ):\n",
    "        \n",
    "        w = tf.get_variable('w', shape=[input.get_shape()[1], out_size], dtype=tf.float32,\n",
    "                         initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable('b', shape=[out_size], dtype=tf.float32,\n",
    "                         initializer=tf.constant_initializer(0.0))\n",
    "        dense = tf.add(tf.matmul(input, w0), b0, name='mat_mul_dense1')\n",
    "        dense = activation(dense)\n",
    "        if batch_norm:\n",
    "            dense = tf.contrib.layers.batch_norm(dense0, is_training = is_train, epsilon=1e-5, decay = 0.9,\n",
    "                                           updates_collections=None, scope = 'dense')  \n",
    "    return bn0\n",
    "\n",
    "def conv1dLayer(input, nfilter, kernel_size, stride, reuse = False):\n",
    "    \n",
    "    out = tf.layers.conv1d(inputs = input, filters = nfilter, kernel_size = kernel_size,\n",
    "                        strides = stride, padding = 'valid', data_format ='channels_last',\n",
    "                        dilation_rate = 1, activation = None,\n",
    "                        use_bias = True, kernel_initializer = tf.truncated_normal_initializer(stddev=0.02),\n",
    "                        bias_initializer = tf.constant_initializer(0.0),\n",
    "                        kernel_regularizer = tf.keras.regularizers.l2(l=0.01),\n",
    "                        name='conv1d_layer', reuse = reuse)\n",
    "    return out\n",
    "def dense_encoder(input, fps_dim, layers_dim, is_train_enc, reuse=False)\n",
    "    \n",
    "\n",
    "    with tf.variable_scope('dense_class') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "        with tf.variable_scope('Layer0')\n",
    "            out_layer0 = denseLayer(input,layers_dim[0])\n",
    "            \n",
    "        with tf.variable_scope('Layer1')\n",
    "            out_layer1 = denseLayer(out_layer0,layers_dim[1])\n",
    "        \n",
    "        with tf.variable_scope('Layer2')\n",
    "            out_layer2 = denseLayer(out_layer1, layers_dim[2], activation = linear)\n",
    "    return out_layer2\n",
    "        \n",
    "\n",
    "def cnn_encoder(input, fps_dim, layers_dim, is_train_enc, reuse=False):\n",
    "\n",
    "    with tf.variable_scope('encode') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "        \n",
    "        #Convolution module M\n",
    "        with tf.variable_scope('first_layer')\n",
    "            out_layer1 = conv1dLayer(input, nfilter=64, kernel_size = 32, stride = 6, reuse = reuse)\n",
    "            out_layer1 = lrelu(out_layer1, leak = 0.1)\n",
    "            \n",
    "        with tf.variable_scope('second_layer')\n",
    "            out_layer2 = conv1dLayer(out_layer1, nfilter=64, kernel_size = 16, stride = 4, reuse = reuse)\n",
    "            out_layer2 = lrelu(out_layer2, leak = 0.1)\n",
    "        \n",
    "        \n",
    "        out_layer3 = tf.layers.dropout(out_layer2, rate=0.3)\n",
    "        \n",
    "        with tf.variable_scope('fourth_layer')\n",
    "            out_layer4 = conv1dLayer(out_layer1, nfilter=92, kernel_size = 8, stride = 3, reuse = reuse)\n",
    "            out_layer4 = lrelu(out_layer4, leak = 0.1)\n",
    "        \n",
    "        with tf.variable_scope('fifth_layer')\n",
    "            with tf.variable_scope('second_layer')\n",
    "            out_layer5 = conv1dLayer(out_layer4, nfilter=128, kernel_size = 5, stride = 3, reuse = reuse)\n",
    "            out_layer5 = lrelu(out_layer1, leak = 0.1)\n",
    "            out_layer5 = tf.layers.batch_normalization(out_layer5)        \n",
    "            out_layer5 = tf.layers.dropout(out_layer5, rate=0.3)\n",
    "\n",
    "        #Flattening \n",
    "        out_flat = tf.layers.flatten(out_layer5, name = 'encode_flatten')\n",
    "        \n",
    "        # Input layer (layers_dim[0]) encoding layer\n",
    "        with tf.variable_scope('sixth_layer')\n",
    "            out_layer6 = denseLayer(out_flat, 40)\n",
    "\n",
    "        with tf.variable_scope('seventh_layer')\n",
    "            out_latent = denseLayer(out_layer6, 10, activation = linear)\n",
    "        sizes_encoder = {}\n",
    "        sizes_encoder['enc_input'] = input.get_shape().as_list()\n",
    "        sizes_encoder['cnn1_out'] = out_cnn1.get_shape().as_list()\n",
    "        sizes_encoder['cnn2_out'] = out_cnn2.get_shape().as_list()\n",
    "        sizes_encoder['dpu1_out'] = out_dpu1.get_shape().as_list()\n",
    "        sizes_encoder['cnn3_out'] = out_cnn3.get_shape().as_list()\n",
    "        sizes_encoder['cnn4_out'] = out_cnn4.get_shape().as_list()\n",
    "        sizes_encoder['dpu2_out'] = out_dpu2.get_shape().as_list()\n",
    "        sizes_encoder['flatten'] = out_flat.get_shape().as_list()\n",
    "        sizes_encoder['bn0'] = bn0.get_shape().as_list()\n",
    "        sizes_encoder['bn1'] = bn1.get_shape().as_list()\n",
    "                                                        \n",
    "        return bn1, sizes_encoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
